{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c24b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import cv2, numpy as np, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901f5dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫£i model YOLO c√≥ s·∫µn (s·∫Ω t·ª± ƒë·ªông download l·∫ßn ƒë·∫ßu)\n",
    "print(\"üì• ƒêang t·∫£i YOLOv8 nano model...\")\n",
    "model = YOLO(\"yolov8n.pt\")  # D√πng nano version cho t·ªëc ƒë·ªô\n",
    "\n",
    "print(\"‚úÖ Model ƒë√£ s·∫µn s√†ng!\")\n",
    "print(f\"üìä Model c√≥ th·ªÉ detect {len(model.names)} classes:\")\n",
    "\n",
    "# In ra c√°c class model c√≥ th·ªÉ detect\n",
    "for i, name in model.names.items():\n",
    "    print(f\"{i:2d}: {name}\")\n",
    "\n",
    "# T√¨m class li√™n quan ƒë·∫øn vehicle\n",
    "vehicle_classes = [\n",
    "    (i, name)\n",
    "    for i, name in model.names.items()\n",
    "    if any(keyword in name.lower() for keyword in [\"car\", \"truck\", \"bus\", \"motorcycle\"])\n",
    "]\n",
    "print(f\"\\nüöó Vehicle classes: {vehicle_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bf8c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference v·ªõi model fine-tune (best.pt) tr√™n ·∫£nh sample\n",
    "\n",
    "WEIGHT_PATH = 'best.pt'  # ƒë·ªïi n·∫øu file n·∫±m ·ªü th∆∞ m·ª•c kh√°c, v√≠ d·ª•: 'runs/detect/train/weights/best.pt'\n",
    "IMAGE_PATH = 'images/sample_plate.png'\n",
    "\n",
    "if not os.path.exists(WEIGHT_PATH):\n",
    "    raise FileNotFoundError(f'Kh√¥ng t√¨m th·∫•y weight t·∫°i: {WEIGHT_PATH}')\n",
    "if not os.path.exists(IMAGE_PATH):\n",
    "    raise FileNotFoundError(f'Kh√¥ng t√¨m th·∫•y ·∫£nh m·∫´u t·∫°i: {IMAGE_PATH}')\n",
    "\n",
    "plate_model = YOLO(WEIGHT_PATH)\n",
    "print('‚úÖ Loaded fine-tuned model. Classes:', plate_model.names)\n",
    "\n",
    "img_bgr = cv2.imread(IMAGE_PATH)\n",
    "if img_bgr is None:\n",
    "    raise RuntimeError('Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh (c√≥ th·ªÉ h·ªèng ho·∫∑c sai ƒë·ªãnh d·∫°ng).')\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Ch·∫°y inference\n",
    "results = plate_model(img_bgr, conf=0.25, imgsz=640, verbose=False)\n",
    "res = results[0]\n",
    "boxes = res.boxes\n",
    "print(f'üîç S·ªë v√πng detect: {len(boxes) if boxes is not None else 0}')\n",
    "\n",
    "annotated = res.plot()  # ·∫£nh ƒë√£ v·∫Ω box\n",
    "\n",
    "# Thu th·∫≠p crop v√† (chu·∫©n b·ªã) refine 4 g√≥c\n",
    "plate_crops = []\n",
    "refined_polygons = []\n",
    "if boxes is not None:\n",
    "    for b in boxes:\n",
    "        xyxy = b.xyxy[0].cpu().numpy().astype(int)\n",
    "        x1, y1, x2, y2 = xyxy\n",
    "        crop = img_bgr[y1:y2, x1:x2]\n",
    "        if crop.size == 0:\n",
    "            continue\n",
    "        plate_crops.append({'bbox': (x1,y1,x2,y2), 'crop': crop})\n",
    "        # Corner refinement ƒë∆°n gi·∫£n b·∫±ng contour (n·∫øu c·∫ßn)\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "        edges = cv2.Canny(blur, 50, 150)\n",
    "        cnts, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if cnts:\n",
    "            cnt = max(cnts, key=cv2.contourArea)\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.03 * peri, True)\n",
    "            if len(approx) == 4:\n",
    "                pts = approx.reshape(4,2).astype(float)\n",
    "                # D·ªãch ƒëi·ªÉm v·ªÅ to·∫° ƒë·ªô g·ªëc ·∫£nh\n",
    "                pts[:,0] += x1\n",
    "                pts[:,1] += y1\n",
    "                refined_polygons.append(pts)\n",
    "\n",
    "print(f'üñºÔ∏è S·ªë crop t·∫°o ƒë∆∞·ª£c: {len(plate_crops)}')\n",
    "print(f'üìê S·ªë polygon 4 ƒëi·ªÉm t√¨m ƒë∆∞·ª£c: {len(refined_polygons)}')\n",
    "\n",
    "# Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "fig_cols = 2 + (1 if plate_crops else 0)\n",
    "plt.figure(figsize=(5*fig_cols,5))\n",
    "plt.subplot(1, fig_cols, 1)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title('·∫¢nh g·ªëc')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, fig_cols, 2)\n",
    "plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Detect (bbox)')\n",
    "plt.axis('off')\n",
    "\n",
    "if plate_crops:\n",
    "    first = plate_crops[0]['crop']\n",
    "    plt.subplot(1, fig_cols, 3)\n",
    "    plt.imshow(cv2.cvtColor(first, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Crop bi·ªÉn s·ªë (ƒë·∫ßu ti√™n)')\n",
    "    plt.axis('off')\n",
    "\n",
    "# V·∫Ω polygon n·∫øu c√≥\n",
    "if refined_polygons:\n",
    "    poly_img = img_rgb.copy()\n",
    "    for pts in refined_polygons:\n",
    "        pts_int = pts.astype(int)\n",
    "        cv2.polylines(poly_img, [pts_int], True, (255,0,0), 2)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(poly_img)\n",
    "    plt.title('Polygon 4 g√≥c (refine)')\n",
    "    plt.axis('off')\n",
    "\n",
    "print('\\n‚û°Ô∏è NEXT: C√≥ th·ªÉ warp ·∫£nh b·∫±ng 4 ƒëi·ªÉm n·∫øu polygon ƒë√£ ·ªïn (th√™m h√†m warp).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5fa343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== DEBUG CELL: Qu√©t tham s·ªë & in th√¥ng tin chi ti·∫øt ====\n",
    "# M·ª•c ti√™u:\n",
    "# 1. Ki·ªÉm tra weight (t·ªìn t·∫°i, k√≠ch th∆∞·ªõc, th·ªùi gian s·ª≠a ƒë·ªïi) + working directory\n",
    "# 2. In metadata model: task, classes\n",
    "# 3. Qu√©t nhi·ªÅu m·ª©c conf & imgsz ƒë·ªÉ xem c√≥ box n√†o xu·∫•t hi·ªán kh√¥ng\n",
    "# 4. In raw tensor (xyxy, conf, cls) c·ªßa box ƒë·∫ßu ti√™n khi t√¨m th·∫•y\n",
    "# 5. Corner refinement c·∫£i ti·∫øn (adaptive threshold + fallback minAreaRect) cho box ƒë·∫ßu ti√™n\n",
    "# 6. T·∫°o summary cu·ªëi c√πng ƒë·ªÉ bi·∫øt d·ª´ng ·ªü b∆∞·ªõc n√†o\n",
    "\n",
    "import os, time, math, cv2, numpy as np, torch\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "summary = {}\n",
    "\n",
    "print(\"== 1. FILE & ENVIRON ==\")\n",
    "wd = os.getcwd()\n",
    "summary['cwd'] = wd\n",
    "print(\"cwd:\", wd)\n",
    "print(\"Python:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# Ki·ªÉm tra WEIGHT_PATH, IMAGE_PATH (d√πng bi·∫øn ƒë√£ c√≥ t·ª´ cell tr∆∞·ªõc n·∫øu t·ªìn t·∫°i)\n",
    "if 'WEIGHT_PATH' not in globals():\n",
    "    WEIGHT_PATH = 'best.pt'\n",
    "if 'IMAGE_PATH' not in globals():\n",
    "    IMAGE_PATH = 'images/sample_plate.png'\n",
    "\n",
    "summary['weight_path'] = WEIGHT_PATH\n",
    "summary['image_path'] = IMAGE_PATH\n",
    "\n",
    "if not os.path.exists(WEIGHT_PATH):\n",
    "    raise FileNotFoundError(f\"Kh√¥ng th·∫•y weight: {WEIGHT_PATH}\")\n",
    "if not os.path.exists(IMAGE_PATH):\n",
    "    raise FileNotFoundError(f\"Kh√¥ng th·∫•y ·∫£nh: {IMAGE_PATH}\")\n",
    "\n",
    "size = os.path.getsize(WEIGHT_PATH)\n",
    "mtime = datetime.fromtimestamp(os.path.getmtime(WEIGHT_PATH))\n",
    "print(f\"Weight size: {size} bytes | modified: {mtime}\")\n",
    "summary['weight_size'] = size\n",
    "summary['weight_mtime'] = str(mtime)\n",
    "\n",
    "print(\"\\n== 2. LOAD MODEL (n·∫øu ch∆∞a) ==\")\n",
    "if 'plate_model' not in globals():\n",
    "    plate_model = YOLO(WEIGHT_PATH)\n",
    "    print(\"Loaded model fresh.\")\n",
    "else:\n",
    "    # Force reload ƒë·ªÉ ch·∫Øc ch·∫Øn kh√¥ng cache nh·∫ßm (c√≥ th·ªÉ comment l·∫°i n·∫øu kh√¥ng c·∫ßn)\n",
    "    try:\n",
    "        plate_model = YOLO(WEIGHT_PATH)\n",
    "        print(\"Reloaded model to avoid stale state.\")\n",
    "    except Exception as e:\n",
    "        print(\"Reuse existing plate_model (reload failed):\", e)\n",
    "\n",
    "print(\"Task:\", getattr(plate_model, 'task', 'N/A'))\n",
    "print(\"Classes (names):\", plate_model.names)\n",
    "summary['task'] = getattr(plate_model, 'task', 'N/A')\n",
    "summary['classes'] = plate_model.names\n",
    "summary['num_classes'] = len(plate_model.names)\n",
    "\n",
    "print(\"\\n== 3. LOAD IMAGE ==\")\n",
    "img_bgr_dbg = cv2.imread(IMAGE_PATH)\n",
    "if img_bgr_dbg is None:\n",
    "    raise RuntimeError(\"Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh test\")\n",
    "H, W = img_bgr_dbg.shape[:2]\n",
    "print(f\"Image shape: {W}x{H}\")\n",
    "summary['image_shape'] = (H, W)\n",
    "\n",
    "print(\"\\n== 4. SWEEP conf & imgsz ==\")\n",
    "confs = [0.25, 0.15, 0.1, 0.05, 0.02, 0.01]\n",
    "imgszs = [640, 800, 960, 1024]\n",
    "found = False\n",
    "first_result = None\n",
    "chosen = None\n",
    "\n",
    "for c in confs:\n",
    "    if found: break\n",
    "    for sz in imgszs:\n",
    "        t0 = time.time()\n",
    "        try:\n",
    "            r = plate_model(img_bgr_dbg, conf=c, imgsz=sz, verbose=False)[0]\n",
    "        except Exception as e:\n",
    "            print(f\"Error infer conf={c} sz={sz}: {e}\")\n",
    "            continue\n",
    "        dt = (time.time() - t0)*1000\n",
    "        n_boxes = 0 if r.boxes is None else len(r.boxes)\n",
    "        print(f\"conf={c:.3f} imgsz={sz} -> {n_boxes} boxes ({dt:.1f} ms)\")\n",
    "        if n_boxes > 0:\n",
    "            found = True\n",
    "            first_result = r\n",
    "            chosen = (c, sz)\n",
    "            break\n",
    "\n",
    "summary['found_box'] = found\n",
    "summary['chosen_params'] = chosen\n",
    "\n",
    "if not found:\n",
    "    print(\"\\n‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y box n√†o ·ªü m·ªçi m·ª©c conf/imgsz ƒë√£ th·ª≠.\")\n",
    "    print(\"G·ª£i √Ω ti·∫øp: ki·ªÉm tra l·∫°i log training (results.png), dataset labels, ho·∫∑c xem c√≥ train segmentation kh√¥ng.\")\n",
    "    print(\"Summary:\", summary)\n",
    "else:\n",
    "    print(f\"\\n‚úÖ C√≥ box t·∫°i conf={chosen[0]} imgsz={chosen[1]}\")\n",
    "    boxes = first_result.boxes\n",
    "    # In raw tensors (t·ªëi ƒëa 5 box ƒë·∫ßu)\n",
    "    print(\"Raw boxes tensor shape:\", boxes.xyxy.shape)\n",
    "    for i, b in enumerate(boxes):\n",
    "        if i >= 5: break\n",
    "        xyxy = b.xyxy[0].tolist()\n",
    "        confv = float(b.conf[0]) if b.conf is not None else None\n",
    "        clsv = int(b.cls[0]) if b.cls is not None else None\n",
    "        print(f\"Box[{i}] xyxy={['%.1f'%v for v in xyxy]} conf={confv:.4f} cls={clsv}\")\n",
    "\n",
    "    # D√πng box ƒë·∫ßu ti√™n ƒë·ªÉ th·ª≠ corner refinement\n",
    "    b0 = boxes[0]\n",
    "    x1,y1,x2,y2 = b0.xyxy[0].cpu().numpy().astype(int)\n",
    "    x1,y1 = max(0,x1), max(0,y1)\n",
    "    x2,y2 = min(W-1,x2), min(H-1,y2)\n",
    "    crop = img_bgr_dbg[y1:y2, x1:x2]\n",
    "    print(f\"Crop size: {crop.shape if crop.size else None}\")\n",
    "\n",
    "    refined_pts = None\n",
    "\n",
    "    def order_points(pts):\n",
    "        # pts: (4,2)\n",
    "        rect = np.zeros((4,2), dtype=np.float32)\n",
    "        s = pts.sum(axis=1)\n",
    "        rect[0] = pts[np.argmin(s)]  # TL\n",
    "        rect[2] = pts[np.argmax(s)]  # BR\n",
    "        diff = np.diff(pts, axis=1)\n",
    "        rect[1] = pts[np.argmin(diff)]  # TR\n",
    "        rect[3] = pts[np.argmax(diff)]  # BL\n",
    "        return rect\n",
    "\n",
    "    if crop.size > 0:\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        # Adaptive threshold thay v√¨ ch·ªâ Canny\n",
    "        thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY_INV, 21, 9)\n",
    "        # Morphology nh·∫π ƒë·ªÉ l√†m ƒë·∫ßy n√©t b·ªã ƒë·ª©t\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "        cnts, _ = cv2.findContours(thr, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if cnts:\n",
    "            cnt = max(cnts, key=cv2.contourArea)\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "            if len(approx) == 4:\n",
    "                refined_pts = approx.reshape(4,2).astype(float)\n",
    "                refined_pts[:,0] += x1\n",
    "                refined_pts[:,1] += y1\n",
    "                refined_pts = order_points(refined_pts)\n",
    "                print(\"‚úî Polygon 4 ƒëi·ªÉm (approxPolyDP)\")\n",
    "            else:\n",
    "                # Fallback minAreaRect\n",
    "                rrect = cv2.minAreaRect(cnt)\n",
    "                box_pts = cv2.boxPoints(rrect)\n",
    "                refined_pts = box_pts.astype(float)\n",
    "                refined_pts[:,0] += x1\n",
    "                refined_pts[:,1] += y1\n",
    "                refined_pts = order_points(refined_pts)\n",
    "                print(f\"‚Ñπ Fallback minAreaRect (approx={len(approx)} ƒëi·ªÉm)\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y contour trong crop.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Crop r·ªóng.\")\n",
    "\n",
    "    summary['refined_polygon'] = None if refined_pts is None else refined_pts.tolist()\n",
    "\n",
    "    # Visualization\n",
    "    import matplotlib.pyplot as plt\n",
    "    img_show = cv2.cvtColor(img_bgr_dbg.copy(), cv2.COLOR_BGR2RGB)\n",
    "    if refined_pts is not None:\n",
    "        rp_int = refined_pts.astype(int)\n",
    "        cv2.polylines(img_show, [rp_int], True, (0,255,0), 2)\n",
    "    # V·∫Ω bbox ƒë·∫ßu ti√™n\n",
    "    cv2.rectangle(img_show, (x1,y1), (x2,y2), (255,0,0), 2)\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(img_show)\n",
    "    plt.title('Debug: bbox + polygon (n·∫øu c√≥)')\n",
    "    plt.axis('off')\n",
    "\n",
    "print(\"\\n== SUMMARY ==\")\n",
    "for k,v in summary.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "print(\"\\nGhi ch√∫ ti·∫øp theo:\")\n",
    "if not found:\n",
    "    print(\"- X√°c nh·∫≠n l·∫°i task (detect vs segment), dataset labels, log training.\")\n",
    "else:\n",
    "    if summary.get('refined_polygon') is None:\n",
    "        print(\"- C√≥ box nh∆∞ng ch∆∞a ra polygon 4 ƒëi·ªÉm ·ªïn ƒë·ªãnh: th·ª≠ ƒëi·ªÅu ch·ªânh threshold/morph ho·∫∑c tƒÉng resolution.\")\n",
    "    else:\n",
    "        print(\"- ƒê√£ c√≥ polygon -> b∆∞·ªõc k·∫ø ti·∫øp: warp & chu·∫©n ho√° k√≠ch th∆∞·ªõc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7a3724",
   "metadata": {},
   "source": [
    "### üîç Ch·∫©n ƒëo√°n s√¢u ti·∫øp theo (sau khi 0 boxes ·ªü m·ªçi m·ª©c conf)\n",
    "C√°c b∆∞·ªõc d∆∞·ªõi s·∫Ω ki·ªÉm tra:\n",
    "1. Weight `best.pt` c√≥ th·∫≠t s·ª± kh√°c v·ªõi `yolov8n.pt` (hash, k√≠ch th∆∞·ªõc) hay ch·ªâ g·∫ßn nh∆∞ b·∫£n g·ªëc.\n",
    "2. Th∆∞ m·ª•c training (vd: `runs/detect/train*`) c√≥ t·ªìn t·∫°i log (`results.csv`, `results.png`).\n",
    "3. Dataset YAML v√† m·ªôt v√†i nh√£n m·∫´u c√≥ h·ª£p l·ªá (t·ªça ƒë·ªô chu·∫©n YOLO, gi√° tr·ªã trong [0,1]).\n",
    "4. In th·ª≠ raw output shape ƒë·ªÉ xem head c√≥ ho·∫°t ƒë·ªông.\n",
    "\n",
    "Ch·∫°y cell k·∫ø ti·∫øp ƒë·ªÉ thu th·∫≠p th√¥ng tin. N·∫øu thi·∫øu file, n√≥ s·∫Ω c·∫£nh b√°o ch·ª© kh√¥ng d·ª´ng h·∫≥n, gi√∫p ta bi·∫øt thi·∫øu m·∫£nh n√†o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bf5ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== 1. HASH COMPARE base vs best ==\n",
      "yolov8n.pt size: 6549796 hash: 95a2449609c73cd69a072b09daaff0cc\n",
      "best.pt   size: 6247971 hash: 3cd969b2396c92fbf78721d5d1fbc28f\n",
      "‚úÖ Hash kh√°c => weight ƒë√£ thay ƒë·ªïi so v·ªõi base.\n",
      "\n",
      "== 2. LIST training runs (runs/detect/*) ==\n",
      "Found runs: (none)\n",
      "\n",
      "== 3. RESULTS.CSV / results.png ==\n",
      "B·ªè qua v√¨ kh√¥ng t√¨m th·∫•y run.\n",
      "\n",
      "== 4. SEARCH data.yaml ==\n",
      "Candidate yamls: ['License Plate.v1i.yolov8/data.yaml']\n",
      "-- License Plate.v1i.yolov8/data.yaml --\n",
      "train: ../train/images\n",
      "val: ../valid/images\n",
      "test: ../test/images\n",
      "\n",
      "nc: 1\n",
      "names: ['Plate']\n",
      "\n",
      "roboflow:\n",
      "  workspace: azazeldev\n",
      "  project: license-plate-zdxng-hc6rl\n",
      "  version: 1\n",
      "  license: CC BY 4.0\n",
      "  url: https://universe.roboflow.com/azazeldev/license-plate-zdxng-hc6rl/dataset/1\n",
      "\n",
      "== 5. SAMPLE LABEL FILES (.txt) ==\n",
      "File: License Plate.v1i.yolov8/test/labels/0005_00512_b_jpg.rf.715e6f1e6c145e6c2f541b73715c7e02.txt (n=1)\n",
      "   0 0.5408653846153846 0.6045673076923077 0.22115384615384615 0.24759615384615385\n",
      "File: License Plate.v1i.yolov8/test/labels/0006_05286_b_jpg.rf.e699da8d47c1e9afd1df9bfb43cc76b1.txt (n=1)\n",
      "   0 0.49158653846153844 0.6069711538461539 0.18028846153846154 0.25240384615384615\n",
      "File: License Plate.v1i.yolov8/test/labels/0010_02063_b_jpg.rf.a818f9d3f674898676dd837d35dcce5e.txt (n=1)\n",
      "   0 0.38461538461538464 0.5252403846153846 0.20192307692307693 0.24759615384615385\n",
      "\n",
      "== 6. FORWARD DUMMY TENSOR SHAPE CHECK ==\n",
      "Raw model outputs (len): 2\n",
      "  [0] shape=(1, 5, 8400)\n",
      "  [1] type=<class 'list'>\n",
      "\n",
      "== 7. NEXT ACTION SUGGESTION ==\n",
      "-> Kh√¥ng th·∫•y th∆∞ m·ª•c run: c√≥ th·ªÉ b·∫°n ch·ªâ copy best.pt t·ª´ n∆°i kh√°c, c·∫ßn k√®m logs ƒë·ªÉ x√°c nh·∫≠n.\n",
      "-> Thi·∫øu results.csv: c·∫ßn run training l·∫°i v·ªõi --project ƒë·ªÉ c√≥ logs ho·∫∑c cung c·∫•p ƒë∆∞·ªùng d·∫´n ch√≠nh x√°c.\n",
      "\n",
      "REPORT SUMMARY KEYS:\n",
      "hash_equal: False\n",
      "runs: 0 items\n",
      "yamls: 1 items\n",
      "sample_yaml_excerpt: train: ../train/images\n",
      "val: ../valid/images\n",
      "test: ../test/images\n",
      "\n",
      "nc: 1\n",
      "names: ['Plate']\n",
      "\n",
      "roboflow:\n",
      "  workspace: azazeldev\n",
      "  project: license-plate-zdxng-hc6rl\n",
      "  version: 1\n",
      "  license: CC BY 4.0\n",
      "  url: https://universe.roboflow.com/azazeldev/license-plate-zdxng-hc6rl/dataset/1\n",
      "label_samples: 3 items\n",
      "dummy_forward: True\n",
      "\n",
      "N·∫øu c·∫ßn m√¨nh t·∫°o cell warp gi·∫£ l·∫≠p (khi c√≥ polygon) th√¨ g√µ: th√™m cell warp\n"
     ]
    }
   ],
   "source": [
    "# ==== DEEP DIAGNOSTIC CELL ====\n",
    "# M·ª•c ti√™u: x√°c ƒë·ªãnh v√¨ sao model kh√¥ng t·∫°o ra box n√†o.\n",
    "# 1. So s√°nh hash best.pt v·ªõi yolov8n.pt (ƒë·ªÉ xem ƒë√£ fine-tune th·ª±c s·ª±?)\n",
    "# 2. Li·ªát k√™ th∆∞ m·ª•c runs/detect/* ƒë·ªÉ t√¨m run hu·∫•n luy·ªán.\n",
    "# 3. ƒê·ªçc results.csv (n·∫øu c√≥) ƒë·ªÉ xem mAP/loss.\n",
    "# 4. T√¨m dataset yaml (common: data.yaml) trong c√¢y th∆∞ m·ª•c.\n",
    "# 5. L·∫•y ng·∫´u nhi√™n 1-2 file label .txt v√† ki·ªÉm tra ƒë·ªãnh d·∫°ng.\n",
    "# 6. Forward dummy tensor ƒë·ªÉ xem head output shape.\n",
    "# 7. In g·ª£i √Ω h√†nh ƒë·ªông ti·∫øp theo.\n",
    "\n",
    "import os, glob, hashlib, csv, re, textwrap, torch, sys\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "report = {}\n",
    "\n",
    "print(\"== 1. HASH COMPARE base vs best ==\")\n",
    "base_path = 'yolov8n.pt'\n",
    "best_path = WEIGHT_PATH if 'WEIGHT_PATH' in globals() else 'best.pt'\n",
    "base_hash = best_hash = None\n",
    "\n",
    "def file_hash(p):\n",
    "    h = hashlib.md5()\n",
    "    with open(p,'rb') as f:\n",
    "        for chunk in iter(lambda: f.read(8192), b''):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "if os.path.exists(base_path) and os.path.exists(best_path):\n",
    "    base_hash = file_hash(base_path)\n",
    "    best_hash = file_hash(best_path)\n",
    "    print(\"yolov8n.pt size:\", os.path.getsize(base_path), \"hash:\", base_hash)\n",
    "    print(\"best.pt   size:\", os.path.getsize(best_path), \"hash:\", best_hash)\n",
    "    if base_hash == best_hash:\n",
    "        print(\"‚ö†Ô∏è best.pt gi·ªëng h·ªát yolov8n.pt (c√≥ th·ªÉ ch∆∞a fine-tune ho·∫∑c copy nh·∫ßm).\")\n",
    "        report['hash_equal'] = True\n",
    "    else:\n",
    "        print(\"‚úÖ Hash kh√°c => weight ƒë√£ thay ƒë·ªïi so v·ªõi base.\")\n",
    "        report['hash_equal'] = False\n",
    "else:\n",
    "    print(\"Kh√¥ng ƒë·ªß file ƒë·ªÉ so s√°nh hash.\")\n",
    "\n",
    "print(\"\\n== 2. LIST training runs (runs/detect/*) ==\")\n",
    "run_dirs = sorted(glob.glob('runs/detect/*'))\n",
    "print(\"Found runs:\", run_dirs if run_dirs else \"(none)\")\n",
    "report['runs'] = run_dirs\n",
    "\n",
    "# ƒêo√°n run g·∫ßn nh·∫•t\n",
    "train_run = None\n",
    "if run_dirs:\n",
    "    train_run = max(run_dirs, key=lambda d: os.path.getmtime(d))\n",
    "    print(\"Ch·ªçn run m·ªõi nh·∫•t:\", train_run)\n",
    "\n",
    "print(\"\\n== 3. RESULTS.CSV / results.png ==\")\n",
    "if train_run:\n",
    "    res_csv = Path(train_run)/'results.csv'\n",
    "    res_png = Path(train_run)/'results.png'\n",
    "    if res_csv.exists():\n",
    "        last_row = None\n",
    "        with open(res_csv,'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            header = next(reader, None)\n",
    "            for row in reader:\n",
    "                last_row = row\n",
    "        print(\"Header:\", header)\n",
    "        print(\"Last epoch row:\", last_row)\n",
    "        report['results_last'] = {'header': header, 'row': last_row}\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Kh√¥ng th·∫•y results.csv trong run.\")\n",
    "    print(\"results.png t·ªìn t·∫°i:\", res_png.exists())\n",
    "else:\n",
    "    print(\"B·ªè qua v√¨ kh√¥ng t√¨m th·∫•y run.\")\n",
    "\n",
    "print(\"\\n== 4. SEARCH data.yaml ==\")\n",
    "yaml_paths = glob.glob('**/data.yaml', recursive=True) + glob.glob('**/dataset.yaml', recursive=True) + glob.glob('**/plate*.yaml', recursive=True)\n",
    "print(\"Candidate yamls:\", yaml_paths if yaml_paths else \"(none)\")\n",
    "report['yamls'] = yaml_paths\n",
    "sample_yaml_content = None\n",
    "for yp in yaml_paths:\n",
    "    try:\n",
    "        with open(yp,'r') as f:\n",
    "            txt = f.read()\n",
    "        print(f\"-- {yp} --\\n\" + '\\n'.join(txt.splitlines()[:30]))\n",
    "        sample_yaml_content = txt\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(\"Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c\", yp, e)\n",
    "report['sample_yaml_excerpt'] = None if sample_yaml_content is None else '\\n'.join(sample_yaml_content.splitlines()[:30])\n",
    "\n",
    "print(\"\\n== 5. SAMPLE LABEL FILES (.txt) ==\")\n",
    "# T√¨m t·ªëi ƒëa 3 file .txt trong labels train/val\n",
    "label_files = glob.glob('**/labels/**/*.txt', recursive=True)\n",
    "label_sample = label_files[:3]\n",
    "if not label_sample:\n",
    "    print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file labels/**/*.txt\")\n",
    "else:\n",
    "    for lf in label_sample:\n",
    "        try:\n",
    "            with open(lf,'r') as f:\n",
    "                lines = [ln.strip() for ln in f.readlines() if ln.strip()]\n",
    "            print(f\"File: {lf} (n={len(lines)})\")\n",
    "            for ln in lines[:5]:\n",
    "                print(\"  \", ln)\n",
    "                parts = ln.split()\n",
    "                if len(parts) >= 5:\n",
    "                    cls_id = parts[0]\n",
    "                    coords = list(map(float, parts[1:5]))\n",
    "                    if any(c < 0 or c > 1 for c in coords):\n",
    "                        print(\"    ‚ö†Ô∏è To·∫° ƒë·ªô ngo√†i [0,1] => format sai?\")\n",
    "                else:\n",
    "                    print(\"    ‚ö†Ô∏è D√≤ng kh√¥ng ƒë·ªß 5 ph·∫ßn t·ª≠ (class + 4 s·ªë)\")\n",
    "        except Exception as e:\n",
    "            print(\"  L·ªói ƒë·ªçc:\", e)\n",
    "report['label_samples'] = label_sample\n",
    "\n",
    "print(\"\\n== 6. FORWARD DUMMY TENSOR SHAPE CHECK ==\")\n",
    "# T·∫°o input gi·∫£ (1,3,640,640) v√† forward ƒë·ªÉ xem head output (s·ª≠ d·ª•ng model.model)\n",
    "try:\n",
    "    device = plate_model.model.device if hasattr(plate_model.model, 'device') else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    dummy = torch.zeros(1,3,640,640).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = plate_model.model(dummy)  # raw outputs list\n",
    "    if isinstance(out, (list, tuple)):\n",
    "        print(\"Raw model outputs (len):\", len(out))\n",
    "        for i, o in enumerate(out):\n",
    "            try:\n",
    "                print(f\"  [{i}] shape={tuple(o.shape)}\")\n",
    "            except Exception:\n",
    "                print(f\"  [{i}] type={type(o)}\")\n",
    "    else:\n",
    "        print(\"Single output shape:\", getattr(out,'shape', type(out)))\n",
    "    report['dummy_forward'] = True\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Dummy forward l·ªói:\", e)\n",
    "    report['dummy_forward'] = False\n",
    "\n",
    "print(\"\\n== 7. NEXT ACTION SUGGESTION ==\")\n",
    "# Logic g·ª£i √Ω\n",
    "if report.get('hash_equal') is True:\n",
    "    print(\"-> Weight tr√πng base: c·∫ßn ki·ªÉm tra l·∫°i qu√° tr√¨nh train, c√≥ ch·∫Øc ƒë√£ fine-tune v√† copy ƒë√∫ng file best.pt?\")\n",
    "else:\n",
    "    if not run_dirs:\n",
    "        print(\"-> Kh√¥ng th·∫•y th∆∞ m·ª•c run: c√≥ th·ªÉ b·∫°n ch·ªâ copy best.pt t·ª´ n∆°i kh√°c, c·∫ßn k√®m logs ƒë·ªÉ x√°c nh·∫≠n.\")\n",
    "    if report.get('results_last') is None:\n",
    "        print(\"-> Thi·∫øu results.csv: c·∫ßn run training l·∫°i v·ªõi --project ƒë·ªÉ c√≥ logs ho·∫∑c cung c·∫•p ƒë∆∞·ªùng d·∫´n ch√≠nh x√°c.\")\n",
    "    if not label_files:\n",
    "        print(\"-> Kh√¥ng t√¨m labels: cung c·∫•p c·∫•u tr√∫c dataset ƒë·ªÉ ki·ªÉm tra.\")\n",
    "\n",
    "print(\"\\nREPORT SUMMARY KEYS:\")\n",
    "for k,v in report.items():\n",
    "    if isinstance(v, (list, tuple)):\n",
    "        print(f\"{k}: {len(v)} items\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "print(\"\\nN·∫øu c·∫ßn m√¨nh t·∫°o cell warp gi·∫£ l·∫≠p (khi c√≥ polygon) th√¨ g√µ: th√™m cell warp\")rtsp://hungchim:12345678@192.168.100.220:554/stream1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
