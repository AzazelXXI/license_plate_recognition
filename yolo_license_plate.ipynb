{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9653af5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12809 label files under 'labels' folders\n",
      "Inferred keypoints K (majority) = 2\n",
      "Images dirs (raw): {'train': 'dataset/images/train', 'val': 'dataset/images/val', 'test': None}\n",
      "Images dirs (normalized): {'train': 'images/train', 'val': 'images/val', 'test': None}\n",
      "Wrote dataset/data.yaml\n",
      "path: /home/azazel/creation/license_plate_recognition/dataset\n",
      "train: images/train\n",
      "val: images/val\n",
      "test: null\n",
      "names:\n",
      "- plate\n",
      "kpt_shape:\n",
      "- 2\n",
      "- 3\n",
      "skeleton: []\n",
      "flip_idx:\n",
      "- 0\n",
      "- 1\n",
      "\n",
      "Removed cache: dataset/labels/train.cache\n",
      "Removed cache: dataset/labels/val.cache\n"
     ]
    }
   ],
   "source": [
    "# 2) Dataset scan + build data.yaml for pose (robust scan)\n",
    "from pathlib import Path\n",
    "import os, yaml\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "\n",
    "root = Path('./dataset')\n",
    "assert root.exists(), \"Dataset folder './dataset' not found. Please scp/rsync it first.\"\n",
    "\n",
    "# Find YOLO label .txt anywhere under labels/ (supports both layouts)\n",
    "label_txts = []\n",
    "label_txts += glob(str(root / 'labels' / '**' / '*.txt'), recursive=True)          # type-first: dataset/labels/train/*.txt\n",
    "label_txts += glob(str(root / '*' / 'labels' / '**' / '*.txt'), recursive=True)    # split-first: dataset/train/labels/*.txt\n",
    "label_txts = sorted(set(label_txts))\n",
    "print(f\"Found {len(label_txts)} label files under 'labels' folders\")\n",
    "\n",
    "if len(label_txts) == 0:\n",
    "    # Last resort: search any .txt and warn\n",
    "    label_txts = glob(str(root / '**' / '*.txt'), recursive=True)\n",
    "    print(f\"Fallback: found {len(label_txts)} .txt files total\")\n",
    "    assert len(label_txts)>0, \"No label .txt files found anywhere in './dataset'. Expected YOLO-pose labels under .../labels/...\"\n",
    "\n",
    "# Robustly infer keypoints K by majority across many labels\n",
    "kp_counter = Counter()\n",
    "for i, fp in enumerate(label_txts[:2000]):  # sample up to 2000 files\n",
    "    try:\n",
    "        with open(fp, 'r') as f:\n",
    "            for j, ln in enumerate(f):\n",
    "                ln = ln.strip()\n",
    "                if not ln:\n",
    "                    continue\n",
    "                parts = ln.split()\n",
    "                # prefer full pose labels: cls cx cy w h + 3*K\n",
    "                if len(parts) >= 8 and (len(parts) - 5) % 3 == 0:\n",
    "                    Kcand = (len(parts) - 5) // 3\n",
    "                    kp_counter[Kcand] += 1\n",
    "                # stop early per file after a couple of lines\n",
    "                if j >= 2:\n",
    "                    break\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "if not kp_counter:\n",
    "    # Fallback: detect K from kpt-only (cls x1 y1 x2 y2 ...)\n",
    "    kpt_only_counter = Counter()\n",
    "    for i, fp in enumerate(label_txts[:2000]):\n",
    "        try:\n",
    "            with open(fp, 'r') as f:\n",
    "                for j, ln in enumerate(f):\n",
    "                    ln = ln.strip()\n",
    "                    if not ln:\n",
    "                        continue\n",
    "                    parts = ln.split()\n",
    "                    if len(parts) >= 3 and (len(parts) - 1) % 2 == 0:\n",
    "                        Kcand = (len(parts) - 1) // 2\n",
    "                        kpt_only_counter[Kcand] += 1\n",
    "                    if j >= 2:\n",
    "                        break\n",
    "        except Exception:\n",
    "            continue\n",
    "    assert kpt_only_counter, 'Could not infer keypoints K from labels.'\n",
    "    K = max(kpt_only_counter, key=kpt_only_counter.get)\n",
    "else:\n",
    "    K = max(kp_counter, key=kp_counter.get)\n",
    "\n",
    "print(f\"Inferred keypoints K (majority) = {K}\")\n",
    "\n",
    "# Heuristics to resolve images dirs for each split\n",
    "def choose_images_dir(split: str):\n",
    "    candidates = [\n",
    "        root / 'images' / split,       # type-first\n",
    "        root / split / 'images',       # split-first\n",
    "    ]\n",
    "    # derive from labels/<split>\n",
    "    split_label_dirs = []\n",
    "    for p in label_txts:\n",
    "        p_norm = p.replace('\\\\', '/').lower()\n",
    "        if f\"/labels/{split}/\" in p_norm:\n",
    "            split_label_dirs.append(Path(p).parent)\n",
    "    if split_label_dirs:\n",
    "        ldir = split_label_dirs[0]\n",
    "        candidates += [\n",
    "            ldir.parent / 'images',                  # .../train/images\n",
    "            ldir.parent.parent / 'images' / ldir.name # .../images/train\n",
    "        ]\n",
    "    for c in candidates:\n",
    "        if c.exists():\n",
    "            return str(c)\n",
    "    return None\n",
    "\n",
    "train_path = choose_images_dir('train')\n",
    "val_path = choose_images_dir('val')\n",
    "test_path = choose_images_dir('test')\n",
    "print('Images dirs (raw):', {'train': train_path, 'val': val_path, 'test': test_path})\n",
    "\n",
    "# Normalize to be RELATIVE to dataset root if possible, else absolute\n",
    "root_abs = root.resolve()\n",
    "\n",
    "def to_rel_or_abs(p):\n",
    "    if not p:\n",
    "        return None\n",
    "    p_abs = Path(p)\n",
    "    try:\n",
    "        p_abs = p_abs.resolve()\n",
    "    except Exception:\n",
    "        p_abs = (root / p).resolve()\n",
    "    try:\n",
    "        return str(p_abs.relative_to(root_abs))\n",
    "    except ValueError:\n",
    "        return str(p_abs)\n",
    "\n",
    "train_rel = to_rel_or_abs(train_path)\n",
    "val_rel = to_rel_or_abs(val_path)\n",
    "test_rel = to_rel_or_abs(test_path)\n",
    "print('Images dirs (normalized):', {'train': train_rel, 'val': val_rel, 'test': test_rel})\n",
    "\n",
    "assert train_rel and val_rel, (\n",
    "    \"Could not locate images/train and/or images/val. Ensure YOLO structure like:\\n\"\n",
    "    \"- dataset/images/train & dataset/labels/train\\n\"\n",
    "    \"- dataset/train/images & dataset/train/labels\\n\"\n",
    ")\n",
    "\n",
    "# Build YAML for pose\n",
    "names = ['plate']\n",
    "skeleton = [[0,1],[1,2],[2,3],[3,0]] if K==4 else []\n",
    "flip_idx = list(range(K))\n",
    "\n",
    "data = {\n",
    "    'path': str(root_abs),\n",
    "    'train': train_rel,\n",
    "    'val': val_rel,\n",
    "    'test': test_rel,\n",
    "    'names': names,\n",
    "    'kpt_shape': [K, 3],\n",
    "    'skeleton': skeleton,\n",
    "    'flip_idx': flip_idx,\n",
    "}\n",
    "\n",
    "yaml_path = root/'data.yaml'\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.safe_dump(data, f, sort_keys=False)\n",
    "\n",
    "print('Wrote', yaml_path)\n",
    "print(yaml.safe_dump(data, sort_keys=False))\n",
    "\n",
    "# Clear label caches so Ultralytics rebuilds with the corrected kpt_shape\n",
    "for cache_name in ['train.cache', 'val.cache']:\n",
    "    cp = root / 'labels' / cache_name\n",
    "    if cp.exists():\n",
    "        try:\n",
    "            os.remove(cp)\n",
    "            print('Removed cache:', cp)\n",
    "        except Exception as e:\n",
    "            print('Failed to remove cache', cp, e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df84a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.b) Merge extra datasets (datasets2 + dataset3/LP_detection) into ./dataset\n",
    "from pathlib import Path\n",
    "import shutil, os, glob\n",
    "\n",
    "root_main = Path('./dataset')\n",
    "root_ds2 = Path('./datasets2')\n",
    "root_ds3 = Path('./dataset3/LP_detection')  # use LP_detection split in dataset3\n",
    "\n",
    "assert root_main.exists(), \"./dataset must exist (target)\"\n",
    "print('Target dataset:', root_main.resolve())\n",
    "\n",
    "# Ensure subfolders\n",
    "for p in [root_main/'images'/ 'train', root_main/'images'/'val', root_main/'labels'/'train', root_main/'labels'/'val']:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Helper to copy tree contents (images + labels) preserving names\n",
    "IMG_EXTS = {'.jpg','.jpeg','.png','.bmp','.tif','.tiff','.webp'}\n",
    "\n",
    "def copy_split(src_images: Path, src_labels: Path, dst_images: Path, dst_labels: Path):\n",
    "    if src_images and src_images.exists():\n",
    "        files = [p for p in src_images.rglob('*') if p.suffix.lower() in IMG_EXTS]\n",
    "        print(f'Copying {len(files)} images from', src_images)\n",
    "        for fp in files:\n",
    "            rel = fp.name\n",
    "            shutil.copy2(fp, dst_images/rel)\n",
    "    if src_labels and src_labels.exists():\n",
    "        files = list(src_labels.rglob('*.txt'))\n",
    "        print(f'Copying {len(files)} labels from', src_labels)\n",
    "        for fp in files:\n",
    "            rel = fp.name\n",
    "            shutil.copy2(fp, dst_labels/rel)\n",
    "\n",
    "# Merge from datasets2 (assumes YOLO layout)\n",
    "if root_ds2.exists():\n",
    "    copy_split(root_ds2/'images'/'train', root_ds2/'labels'/'train', root_main/'images'/'train', root_main/'labels'/'train')\n",
    "    copy_split(root_ds2/'images'/'val',   root_ds2/'labels'/'val',   root_main/'images'/'val',   root_main/'labels'/'val')\n",
    "else:\n",
    "    print('datasets2 not found, skip')\n",
    "\n",
    "# Merge from dataset3/LP_detection (assumes YOLO layout)\n",
    "if root_ds3.exists():\n",
    "    copy_split(root_ds3/'images'/'train', root_ds3/'labels'/'train', root_main/'images'/'train', root_main/'labels'/'train')\n",
    "    copy_split(root_ds3/'images'/'val',   root_ds3/'labels'/'val',   root_main/'images'/'val',   root_main/'labels'/'val')\n",
    "else:\n",
    "    print('dataset3/LP_detection not found, skip')\n",
    "\n",
    "# Clear caches so Ultralytics reindexes\n",
    "for cache_name in ['train.cache', 'val.cache']:\n",
    "    cp = root_main / 'labels' / cache_name\n",
    "    if cp.exists():\n",
    "        try:\n",
    "            os.remove(cp)\n",
    "            print('Removed cache:', cp)\n",
    "        except Exception as e:\n",
    "            print('Failed to remove cache', cp, e)\n",
    "\n",
    "print('Merge done. Now re-run the data.yaml build cell above to re-assert paths if needed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c2501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (quiet) from: /home/azazel/creation/license_plate_recognition/best.pt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Ultralytics offline: asset not found locally: yolo11n.pt",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Minimal, low-I/O training args\u001b[39;00m\n\u001b[32m     27\u001b[39m train_args = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     28\u001b[39m     data=\u001b[38;5;28mstr\u001b[39m(yaml_path),\n\u001b[32m     29\u001b[39m     imgsz=\u001b[32m640\u001b[39m,        \u001b[38;5;66;03m# smaller image reduces memory/compute\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     seed=\u001b[32m42\u001b[39m,\n\u001b[32m     46\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrain_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     50\u001b[39m     save_dir = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(model, \u001b[33m'\u001b[39m\u001b[33mtrainer\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), \u001b[33m'\u001b[39m\u001b[33msave_dir\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/creation/license_plate_recognition/.venv/lib64/python3.13/site-packages/ultralytics/engine/model.py:801\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    798\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m    800\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.hub_session = \u001b[38;5;28mself\u001b[39m.session  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m801\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    803\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/creation/license_plate_recognition/.venv/lib64/python3.13/site-packages/ultralytics/engine/trainer.py:230\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    227\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/creation/license_plate_recognition/.venv/lib64/python3.13/site-packages/ultralytics/engine/trainer.py:349\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self, world_size)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m world_size > \u001b[32m1\u001b[39m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mself\u001b[39m._setup_ddp(world_size)\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    351\u001b[39m nb = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.train_loader)  \u001b[38;5;66;03m# number of batches\u001b[39;00m\n\u001b[32m    352\u001b[39m nw = \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m.args.warmup_epochs * nb), \u001b[32m100\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.warmup_epochs > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m -\u001b[32m1\u001b[39m  \u001b[38;5;66;03m# warmup iterations\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/creation/license_plate_recognition/.venv/lib64/python3.13/site-packages/ultralytics/engine/trainer.py:286\u001b[39m, in \u001b[36mBaseTrainer._setup_train\u001b[39m\u001b[34m(self, world_size)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.amp \u001b[38;5;129;01mand\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:  \u001b[38;5;66;03m# Single-GPU and DDP\u001b[39;00m\n\u001b[32m    285\u001b[39m     callbacks_backup = callbacks.default_callbacks.copy()  \u001b[38;5;66;03m# backup callbacks as check_amp() resets them\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28mself\u001b[39m.amp = torch.tensor(\u001b[43mcheck_amp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m    287\u001b[39m     callbacks.default_callbacks = callbacks_backup  \u001b[38;5;66;03m# restore callbacks\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK > -\u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m world_size > \u001b[32m1\u001b[39m:  \u001b[38;5;66;03m# DDP\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/creation/license_plate_recognition/.venv/lib64/python3.13/site-packages/ultralytics/utils/checks.py:789\u001b[39m, in \u001b[36mcheck_amp\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    787\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m amp_allclose(\u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43myolo11n.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, im)\n\u001b[32m    790\u001b[39m     LOGGER.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mchecks passed ✅\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    791\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/creation/license_plate_recognition/.venv/lib64/python3.13/site-packages/ultralytics/models/yolo/model.py:83\u001b[39m, in \u001b[36mYOLO.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m = new_instance.\u001b[34m__dict__\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mRTDETR\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.model[-\u001b[32m1\u001b[39m]._get_name():  \u001b[38;5;66;03m# if RTDETR head\u001b[39;00m\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/creation/license_plate_recognition/.venv/lib64/python3.13/site-packages/ultralytics/engine/model.py:153\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m._new(model, task=task, verbose=verbose)\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/creation/license_plate_recognition/.venv/lib64/python3.13/site-packages/ultralytics/engine/model.py:297\u001b[39m, in \u001b[36mModel._load\u001b[39m\u001b[34m(self, weights, task)\u001b[39m\n\u001b[32m    294\u001b[39m weights = checks.check_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(weights).rpartition(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     \u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.ckpt = \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m     \u001b[38;5;28mself\u001b[39m.task = \u001b[38;5;28mself\u001b[39m.model.task\n\u001b[32m    299\u001b[39m     \u001b[38;5;28mself\u001b[39m.overrides = \u001b[38;5;28mself\u001b[39m.model.args = \u001b[38;5;28mself\u001b[39m._reset_ckpt_args(\u001b[38;5;28mself\u001b[39m.model.args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/creation/license_plate_recognition/.venv/lib64/python3.13/site-packages/ultralytics/nn/tasks.py:1549\u001b[39m, in \u001b[36mattempt_load_one_weight\u001b[39m\u001b[34m(weight, device, inplace, fuse)\u001b[39m\n\u001b[32m   1535\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mattempt_load_one_weight\u001b[39m(weight, device=\u001b[38;5;28;01mNone\u001b[39;00m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m, fuse=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1536\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[33;03m    Load a single model weights.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1547\u001b[39m \u001b[33;03m        ckpt (dict): Model checkpoint dictionary.\u001b[39;00m\n\u001b[32m   1548\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1549\u001b[39m     ckpt, weight = \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[32m   1550\u001b[39m     args = {**DEFAULT_CFG_DICT, **(ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mtrain_args\u001b[39m\u001b[33m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[32m   1551\u001b[39m     model = (ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mema\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m]).float()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/creation/license_plate_recognition/.venv/lib64/python3.13/site-packages/ultralytics/nn/tasks.py:1425\u001b[39m, in \u001b[36mtorch_safe_load\u001b[39m\u001b[34m(weight, safe_only)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdownloads\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attempt_download_asset\n\u001b[32m   1424\u001b[39m check_suffix(file=weight, suffix=\u001b[33m\"\u001b[39m\u001b[33m.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m file = \u001b[43mattempt_download_asset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# search online if missing locally\u001b[39;00m\n\u001b[32m   1426\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m temporary_modules(\n\u001b[32m   1428\u001b[39m         modules={\n\u001b[32m   1429\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33multralytics.yolo.utils\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33multralytics.utils\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1437\u001b[39m         },\n\u001b[32m   1438\u001b[39m     ):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36m_local_only\u001b[39m\u001b[34m(asset, *args, **kwargs)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m p.exists():\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(p)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUltralytics offline: asset not found locally: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00masset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Ultralytics offline: asset not found locally: yolo11n.pt"
     ]
    }
   ],
   "source": [
    "# 3) Train (quiet + low-lag)\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import torch, os, logging\n",
    "\n",
    "# Reduce notebook lag/noise\n",
    "os.environ.setdefault('TQDM_DISABLE', '1')  # disable tqdm progress bars\n",
    "os.environ.setdefault('ULTRALYTICS_HUB', '0')\n",
    "os.environ.setdefault('WANDB_DISABLED', 'true')\n",
    "try:\n",
    "    from ultralytics.utils import LOGGER\n",
    "    LOGGER.setLevel(logging.ERROR)  # minimal logs\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Use local data.yaml and local best.pt only\n",
    "yaml_path = Path('./dataset/data.yaml')\n",
    "assert yaml_path.exists(), \"dataset/data.yaml not found. Run the dataset cell first.\"\n",
    "\n",
    "ckpt = str(Path('best.pt').resolve())\n",
    "assert os.path.exists(ckpt), \"best.pt not found at project root. Place your checkpoint at ./best.pt\"\n",
    "\n",
    "print(f'Training (quiet) from: {ckpt}')\n",
    "model = YOLO(ckpt)\n",
    "\n",
    "# Minimal, low-I/O training args\n",
    "train_args = dict(\n",
    "    data=str(yaml_path),\n",
    "    imgsz=640,        # smaller image reduces memory/compute\n",
    "    epochs=200,       # adjust as needed\n",
    "    patience=10,      # early stopping\n",
    "    batch=4,          # tune for your VRAM\n",
    "    device=0 if torch.cuda.is_available() else 'cpu',\n",
    "    workers=int(os.getenv('YOLO_WORKERS', '4')),\n",
    "    rect=True,\n",
    "    cache=os.getenv('YOLO_CACHE', 'disk'),  # use 'disk' to save RAM\n",
    "    pretrained=False,  # do not download any pretrained weights\n",
    "    plots=False,       # no plot generation\n",
    "    save_period=0,     # don't save intermediate epochs\n",
    "    val=False,         # skip per-epoch validation to reduce overhead\n",
    "    verbose=False,     # quiet logs\n",
    "    project='runs',\n",
    "    name='pose_plate',\n",
    "    exist_ok=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "results = model.train(**train_args)\n",
    "try:\n",
    "    save_dir = getattr(getattr(model, 'trainer', None), 'save_dir', None)\n",
    "    if save_dir:\n",
    "        print('Training done. Results saved to:', save_dir)\n",
    "    else:\n",
    "        print('Training done. Check runs/pose_plate for results.')\n",
    "except Exception:\n",
    "    print('Training done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f539c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Validate & quick inference\n",
    "from glob import glob\n",
    "import os, yaml\n",
    "import cv2, numpy as np\n",
    "\n",
    "# Strict offline mode: allow local assets but block any remote downloads\n",
    "os.environ.setdefault('ULTRALYTICS_HUB', '0')\n",
    "os.environ.setdefault('WANDB_DISABLED', 'true')\n",
    "try:\n",
    "    from pathlib import Path as _P\n",
    "    from ultralytics.utils import downloads as _ud\n",
    "    from ultralytics.utils import checks as _uc\n",
    "    _ud.is_online = lambda: False  # type: ignore\n",
    "\n",
    "    def _local_only(asset, *args, **kwargs):\n",
    "        # Return the local path if it exists; otherwise block\n",
    "        try:\n",
    "            p = _P(asset)\n",
    "        except TypeError:\n",
    "            try:\n",
    "                p = _P(asset[0])\n",
    "            except Exception:\n",
    "                p = None\n",
    "        if p is not None and p.exists():\n",
    "            return str(p)\n",
    "        raise RuntimeError(f\"Ultralytics offline: asset not found locally: {asset}\")\n",
    "\n",
    "    for _name in (\"safe_download\", \"attempt_download\", \"attempt_download_asset\", \"get_github_assets\"):\n",
    "        if hasattr(_ud, _name):\n",
    "            setattr(_ud, _name, _local_only)\n",
    "    if hasattr(_uc, \"check_requirements\"):\n",
    "        _uc.check_requirements = lambda *a, **k: None  # type: ignore\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "# Force local checkpoint only (absolute path)\n",
    "ckpt = str(Path('best.pt').resolve())\n",
    "assert os.path.exists(ckpt), \"Local checkpoint './best.pt' not found. Place your trained weights as best.pt at project root.\"\n",
    "print('Loading weights:', ckpt)\n",
    "model = YOLO(ckpt)\n",
    "print('Model task:', getattr(model, 'task', None))\n",
    "\n",
    "# read data.yaml to find val images path\n",
    "with open('./dataset/data.yaml', 'r') as f:\n",
    "    data_cfg = yaml.safe_load(f)\n",
    "val_path = data_cfg.get('val')\n",
    "base_path = data_cfg.get('path', '.')\n",
    "val_dir = os.path.join(base_path, val_path) if val_path else './dataset/val/images'\n",
    "\n",
    "# pick a few images\n",
    "val_imgs = []\n",
    "for pat in ['*.jpg', '*.jpeg', '*.png', '*.*']:\n",
    "    val_imgs = glob(os.path.join(val_dir, pat))\n",
    "    if val_imgs:\n",
    "        break\n",
    "val_imgs = val_imgs[:6]\n",
    "print('Previewing', len(val_imgs), 'images from', val_dir)\n",
    "\n",
    "\n",
    "def _to_numpy(x):\n",
    "    try:\n",
    "        import torch\n",
    "        if isinstance(x, np.ndarray):\n",
    "            return x\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return x.detach().cpu().numpy()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return np.asarray(x)\n",
    "\n",
    "\n",
    "def _order_points_four(pts: np.ndarray) -> np.ndarray:\n",
    "    pts = np.asarray(pts, dtype='float32')\n",
    "    if pts.shape[0] != 4:\n",
    "        return pts\n",
    "    s = pts.sum(axis=1)\n",
    "    diff = pts[:, 1] - pts[:, 0]\n",
    "    tl = pts[np.argmin(s)]\n",
    "    br = pts[np.argmax(s)]\n",
    "    tr = pts[np.argmin(diff)]\n",
    "    bl = pts[np.argmax(diff)]\n",
    "    return np.array([tl, tr, br, bl], dtype='float32')\n",
    "\n",
    "\n",
    "for imgp in val_imgs:\n",
    "    im = cv2.imread(imgp)\n",
    "    res = model.predict(source=im, imgsz=640, conf=0.5, iou=0.6, classes=[0], verbose=False, max_det=50)[0]\n",
    "\n",
    "    # Draw boxes\n",
    "    if res.boxes is not None and len(res.boxes) > 0:\n",
    "        for b in res.boxes:\n",
    "            x1,y1,x2,y2 = b.xyxy[0].int().cpu().tolist()\n",
    "            cv2.rectangle(im, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "\n",
    "    # Draw keypoints with CPU conversion and polygon\n",
    "    if getattr(res, 'keypoints', None) is not None and res.keypoints.xy is not None:\n",
    "        kxy = _to_numpy(res.keypoints.xy)\n",
    "        kcf = _to_numpy(getattr(res.keypoints, 'conf', None)) if getattr(res.keypoints, 'conf', None) is not None else None\n",
    "        for i in range(kxy.shape[0]):\n",
    "            pts = kxy[i]\n",
    "            if pts is None or pts.shape[0] < 4:\n",
    "                continue\n",
    "            mask = np.ones((pts.shape[0],), dtype=bool)\n",
    "            if kcf is not None:\n",
    "                mask = kcf[i] >= 0.1\n",
    "            pts_vis = pts[mask]\n",
    "            if pts_vis.shape[0] >= 4:\n",
    "                pts4 = pts_vis[:4]\n",
    "                ordered = _order_points_four(pts4)\n",
    "                poly = ordered.reshape((-1,1,2)).astype(int)\n",
    "                cv2.polylines(im, [poly], isClosed=True, color=(0,0,255), thickness=2)\n",
    "                for px, py in ordered:\n",
    "                    cv2.circle(im, (int(px), int(py)), 4, (0,255,255), -1)\n",
    "            else:\n",
    "                for px, py in pts[:4]:\n",
    "                    cv2.circle(im, (int(px), int(py)), 4, (0,255,255), -1)\n",
    "\n",
    "    cv2.imshow('preview', im)\n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
