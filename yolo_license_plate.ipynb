{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9653af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Dataset scan + build data.yaml for pose (robust scan)\n",
    "from pathlib import Path\n",
    "import os, yaml\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "\n",
    "root = Path('./dataset')\n",
    "assert root.exists(), \"Dataset folder './dataset' not found. Please scp/rsync it first.\"\n",
    "\n",
    "# Find YOLO label .txt anywhere under labels/ (supports both layouts)\n",
    "label_txts = []\n",
    "label_txts += glob(str(root / 'labels' / '**' / '*.txt'), recursive=True)          # type-first: dataset/labels/train/*.txt\n",
    "label_txts += glob(str(root / '*' / 'labels' / '**' / '*.txt'), recursive=True)    # split-first: dataset/train/labels/*.txt\n",
    "label_txts = sorted(set(label_txts))\n",
    "print(f\"Found {len(label_txts)} label files under 'labels' folders\")\n",
    "\n",
    "if len(label_txts) == 0:\n",
    "    # Last resort: search any .txt and warn\n",
    "    label_txts = glob(str(root / '**' / '*.txt'), recursive=True)\n",
    "    print(f\"Fallback: found {len(label_txts)} .txt files total\")\n",
    "    assert len(label_txts)>0, \"No label .txt files found anywhere in './dataset'. Expected YOLO-pose labels under .../labels/...\"\n",
    "\n",
    "# Robustly infer keypoints K by majority across many labels\n",
    "kp_counter = Counter()\n",
    "for i, fp in enumerate(label_txts[:2000]):  # sample up to 2000 files\n",
    "    try:\n",
    "        with open(fp, 'r') as f:\n",
    "            for j, ln in enumerate(f):\n",
    "                ln = ln.strip()\n",
    "                if not ln:\n",
    "                    continue\n",
    "                parts = ln.split()\n",
    "                # prefer full pose labels: cls cx cy w h + 3*K\n",
    "                if len(parts) >= 8 and (len(parts) - 5) % 3 == 0:\n",
    "                    Kcand = (len(parts) - 5) // 3\n",
    "                    kp_counter[Kcand] += 1\n",
    "                # stop early per file after a couple of lines\n",
    "                if j >= 2:\n",
    "                    break\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "if not kp_counter:\n",
    "    # Fallback: detect K from kpt-only (cls x1 y1 x2 y2 ...)\n",
    "    kpt_only_counter = Counter()\n",
    "    for i, fp in enumerate(label_txts[:2000]):\n",
    "        try:\n",
    "            with open(fp, 'r') as f:\n",
    "                for j, ln in enumerate(f):\n",
    "                    ln = ln.strip()\n",
    "                    if not ln:\n",
    "                        continue\n",
    "                    parts = ln.split()\n",
    "                    if len(parts) >= 3 and (len(parts) - 1) % 2 == 0:\n",
    "                        Kcand = (len(parts) - 1) // 2\n",
    "                        kpt_only_counter[Kcand] += 1\n",
    "                    if j >= 2:\n",
    "                        break\n",
    "        except Exception:\n",
    "            continue\n",
    "    assert kpt_only_counter, 'Could not infer keypoints K from labels.'\n",
    "    K = max(kpt_only_counter, key=kpt_only_counter.get)\n",
    "else:\n",
    "    K = max(kp_counter, key=kp_counter.get)\n",
    "\n",
    "print(f\"Inferred keypoints K (majority) = {K}\")\n",
    "\n",
    "# Heuristics to resolve images dirs for each split\n",
    "def choose_images_dir(split: str):\n",
    "    candidates = [\n",
    "        root / 'images' / split,       # type-first\n",
    "        root / split / 'images',       # split-first\n",
    "    ]\n",
    "    # derive from labels/<split>\n",
    "    split_label_dirs = []\n",
    "    for p in label_txts:\n",
    "        p_norm = p.replace('\\\\', '/').lower()\n",
    "        if f\"/labels/{split}/\" in p_norm:\n",
    "            split_label_dirs.append(Path(p).parent)\n",
    "    if split_label_dirs:\n",
    "        ldir = split_label_dirs[0]\n",
    "        candidates += [\n",
    "            ldir.parent / 'images',                  # .../train/images\n",
    "            ldir.parent.parent / 'images' / ldir.name # .../images/train\n",
    "        ]\n",
    "    for c in candidates:\n",
    "        if c.exists():\n",
    "            return str(c)\n",
    "    return None\n",
    "\n",
    "train_path = choose_images_dir('train')\n",
    "val_path = choose_images_dir('val')\n",
    "test_path = choose_images_dir('test')\n",
    "print('Images dirs (raw):', {'train': train_path, 'val': val_path, 'test': test_path})\n",
    "\n",
    "# Normalize to be RELATIVE to dataset root if possible, else absolute\n",
    "root_abs = root.resolve()\n",
    "\n",
    "def to_rel_or_abs(p):\n",
    "    if not p:\n",
    "        return None\n",
    "    p_abs = Path(p)\n",
    "    try:\n",
    "        p_abs = p_abs.resolve()\n",
    "    except Exception:\n",
    "        p_abs = (root / p).resolve()\n",
    "    try:\n",
    "        return str(p_abs.relative_to(root_abs))\n",
    "    except ValueError:\n",
    "        return str(p_abs)\n",
    "\n",
    "train_rel = to_rel_or_abs(train_path)\n",
    "val_rel = to_rel_or_abs(val_path)\n",
    "test_rel = to_rel_or_abs(test_path)\n",
    "print('Images dirs (normalized):', {'train': train_rel, 'val': val_rel, 'test': test_rel})\n",
    "\n",
    "assert train_rel and val_rel, (\n",
    "    \"Could not locate images/train and/or images/val. Ensure YOLO structure like:\\n\"\n",
    "    \"- dataset/images/train & dataset/labels/train\\n\"\n",
    "    \"- dataset/train/images & dataset/train/labels\\n\"\n",
    ")\n",
    "\n",
    "# Build YAML for pose\n",
    "names = ['plate']\n",
    "skeleton = [[0,1],[1,2],[2,3],[3,0]] if K==4 else []\n",
    "flip_idx = list(range(K))\n",
    "\n",
    "data = {\n",
    "    'path': str(root_abs),\n",
    "    'train': train_rel,\n",
    "    'val': val_rel,\n",
    "    'test': test_rel,\n",
    "    'names': names,\n",
    "    'kpt_shape': [K, 3],\n",
    "    'skeleton': skeleton,\n",
    "    'flip_idx': flip_idx,\n",
    "}\n",
    "\n",
    "yaml_path = root/'data.yaml'\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.safe_dump(data, f, sort_keys=False)\n",
    "\n",
    "print('Wrote', yaml_path)\n",
    "print(yaml.safe_dump(data, sort_keys=False))\n",
    "\n",
    "# Clear label caches so Ultralytics rebuilds with the corrected kpt_shape\n",
    "for cache_name in ['train.cache', 'val.cache']:\n",
    "    cp = root / 'labels' / cache_name\n",
    "    if cp.exists():\n",
    "        try:\n",
    "            os.remove(cp)\n",
    "            print('Removed cache:', cp)\n",
    "        except Exception as e:\n",
    "            print('Failed to remove cache', cp, e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f539c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Validate & quick inference\n",
    "from glob import glob\n",
    "import os, yaml\n",
    "import cv2, numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# locate last run more robustly\n",
    "pose_runs = sorted(glob('runs/pose_plate/*')) if os.path.exists('runs/pose_plate') else []\n",
    "run_dir = pose_runs[-1] if pose_runs else None\n",
    "print('Last run:', run_dir)\n",
    "\n",
    "# Load model from best/last if available, otherwise prefer local yolov8 pose weights\n",
    "ckpt = None\n",
    "if run_dir:\n",
    "    for w in ['weights/best.pt', 'weights/last.pt']:\n",
    "        p = os.path.join(run_dir, w)\n",
    "        if os.path.exists(p):\n",
    "            ckpt = p\n",
    "            break\n",
    "\n",
    "fallback = 'yolov8n-pose.pt'\n",
    "print('Loading weights:', ckpt or fallback)\n",
    "model = YOLO(ckpt or fallback)\n",
    "print('Model task:', getattr(model, 'task', None))\n",
    "\n",
    "# read data.yaml to find val images path\n",
    "with open('./dataset/data.yaml', 'r') as f:\n",
    "    data_cfg = yaml.safe_load(f)\n",
    "val_path = data_cfg.get('val')\n",
    "base_path = data_cfg.get('path', '.')\n",
    "val_dir = os.path.join(base_path, val_path) if val_path else './dataset/val/images'\n",
    "\n",
    "# pick a few images\n",
    "val_imgs = []\n",
    "for pat in ['*.jpg', '*.jpeg', '*.png', '*.*']:\n",
    "    val_imgs = glob(os.path.join(val_dir, pat))\n",
    "    if val_imgs:\n",
    "        break\n",
    "val_imgs = val_imgs[:6]\n",
    "print('Previewing', len(val_imgs), 'images from', val_dir)\n",
    "\n",
    "\n",
    "def _to_numpy(x):\n",
    "    try:\n",
    "        import torch\n",
    "        if isinstance(x, np.ndarray):\n",
    "            return x\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return x.detach().cpu().numpy()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return np.asarray(x)\n",
    "\n",
    "\n",
    "def _order_points_four(pts: np.ndarray) -> np.ndarray:\n",
    "    pts = np.asarray(pts, dtype='float32')\n",
    "    if pts.shape[0] != 4:\n",
    "        return pts\n",
    "    s = pts.sum(axis=1)\n",
    "    diff = pts[:, 1] - pts[:, 0]\n",
    "    tl = pts[np.argmin(s)]\n",
    "    br = pts[np.argmax(s)]\n",
    "    tr = pts[np.argmin(diff)]\n",
    "    bl = pts[np.argmax(diff)]\n",
    "    return np.array([tl, tr, br, bl], dtype='float32')\n",
    "\n",
    "\n",
    "for imgp in val_imgs:\n",
    "    im = cv2.imread(imgp)\n",
    "    res = model.predict(source=im, imgsz=640, conf=0.5, iou=0.6, classes=[0], verbose=False, max_det=50)[0]\n",
    "\n",
    "    # Draw boxes\n",
    "    if res.boxes is not None and len(res.boxes) > 0:\n",
    "        for b in res.boxes:\n",
    "            x1,y1,x2,y2 = b.xyxy[0].int().cpu().tolist()\n",
    "            cv2.rectangle(im, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "\n",
    "    # Draw keypoints with CPU conversion and polygon\n",
    "    if getattr(res, 'keypoints', None) is not None and res.keypoints.xy is not None:\n",
    "        kxy = _to_numpy(res.keypoints.xy)\n",
    "        kcf = _to_numpy(getattr(res.keypoints, 'conf', None)) if getattr(res.keypoints, 'conf', None) is not None else None\n",
    "        for i in range(kxy.shape[0]):\n",
    "            pts = kxy[i]\n",
    "            if pts is None or pts.shape[0] < 4:\n",
    "                continue\n",
    "            mask = np.ones((pts.shape[0],), dtype=bool)\n",
    "            if kcf is not None:\n",
    "                mask = kcf[i] >= 0.1\n",
    "            pts_vis = pts[mask]\n",
    "            if pts_vis.shape[0] >= 4:\n",
    "                pts4 = pts_vis[:4]\n",
    "                ordered = _order_points_four(pts4)\n",
    "                poly = ordered.reshape((-1,1,2)).astype(int)\n",
    "                cv2.polylines(im, [poly], isClosed=True, color=(0,0,255), thickness=2)\n",
    "                for px, py in ordered:\n",
    "                    cv2.circle(im, (int(px), int(py)), 4, (0,255,255), -1)\n",
    "            else:\n",
    "                for px, py in pts[:4]:\n",
    "                    cv2.circle(im, (int(px), int(py)), 4, (0,255,255), -1)\n",
    "\n",
    "    cv2.imshow('preview', im)\n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Train\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import os, glob\n",
    "\n",
    "# Disable cloud sync/telemetry to reduce surprise downloads\n",
    "try:\n",
    "    from ultralytics.utils import SETTINGS\n",
    "    SETTINGS.update({'sync': False})\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "yaml_path = Path('./dataset/data.yaml')\n",
    "assert yaml_path.exists(), 'data.yaml not found; run the dataset YAML cell.'\n",
    "\n",
    "# Remove unrelated YOLOv11/YOLO11 detection weights to avoid accidental selection\n",
    "for pat in ['yolo11*.pt', 'yolov11*.pt']:\n",
    "    for p in glob.glob(pat):\n",
    "        try:\n",
    "            os.remove(p)\n",
    "            print('Removed unrelated weight:', p)\n",
    "        except Exception as e:\n",
    "            print('Could not remove', p, e)\n",
    "\n",
    "model_name = 'yolov8n-pose.pt'  # nano pose model\n",
    "model = YOLO(model_name)\n",
    "print('Using base weights:', model_name, '| task:', getattr(model, 'task', None))\n",
    "\n",
    "# Training options (up to 200 epochs with early stopping)\n",
    "train_args = dict(\n",
    "    data=str(yaml_path),\n",
    "    imgsz=768,        # bigger image size helps pose accuracy\n",
    "    epochs=200,       # train up to 200 epochs\n",
    "    patience=30,      # early stop if no val improvement for 30 epochs\n",
    "    batch=4,          # adjust if you hit OOM\n",
    "    device=0 if torch.cuda.is_available() else 'cpu',\n",
    "    workers=2,        # keep low for laptops\n",
    "    project='runs',\n",
    "    name='pose_plate',\n",
    "    exist_ok=True,\n",
    "    pretrained=False,  # avoid triggering any default weight downloads\n",
    "    cache=False,\n",
    "    plots=True,       # save results.png and curves\n",
    "    save_period=20,   # checkpoint every 20 epochs\n",
    "    seed=42,\n",
    " )\n",
    "\n",
    "results = model.train(**train_args)\n",
    "print('Training done. Best:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99fec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.b) Fine-tune from previous best.pt (creates a new run)\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os, glob, torch\n",
    "\n",
    "# Data YAML must exist\n",
    "yaml_path = Path('./dataset/data.yaml')\n",
    "assert yaml_path.exists(), 'data.yaml not found; ensure it exists before fine-tune.'\n",
    "\n",
    "# Prefer manual checkpoint via env or local path if provided\n",
    "manual_ckpt = os.environ.get('PLATE_WEIGHTS')  # e.g. ./weights/plate_pose_best.pt\n",
    "ckpt = manual_ckpt if manual_ckpt and os.path.exists(manual_ckpt) else None\n",
    "\n",
    "# Try default best path from main training run\n",
    "if not ckpt:\n",
    "    default_best = 'runs/pose_plate/weights/best.pt'\n",
    "    if os.path.exists(default_best):\n",
    "        ckpt = default_best\n",
    "\n",
    "# Otherwise, search all best.pt under runs/**/weights and pick the newest\n",
    "if not ckpt:\n",
    "    bests = glob.glob('runs/**/weights/best.pt', recursive=True)\n",
    "    if bests:\n",
    "        try:\n",
    "            bests.sort(key=lambda p: os.path.getmtime(p))\n",
    "        except Exception:\n",
    "            bests.sort()\n",
    "        ckpt = bests[-1]\n",
    "        print('Picked latest best.pt:', ckpt)\n",
    "\n",
    "# Fallback to base pose weights\n",
    "if not ckpt:\n",
    "    ckpt = 'yolov8n-pose.pt'\n",
    "\n",
    "print('Fine-tuning from:', ckpt)\n",
    "model = YOLO(ckpt)\n",
    "\n",
    "# Safe speed knobs\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision('high')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# RAM usage controls\n",
    "USE_RAM_CACHE = os.environ.get('YOLO_RAM_CACHE', '0') in ('1', 'true', 'True')\n",
    "CACHE_MODE = 'ram' if USE_RAM_CACHE else False\n",
    "WORKERS = int(os.environ.get('YOLO_WORKERS', '4'))  # lower a bit to reduce prefetch memory\n",
    "print(f'Cache mode: {CACHE_MODE} | workers: {WORKERS}')\n",
    "\n",
    "# Moderate, stable fine-tune config\n",
    "train_args = dict(\n",
    "    data=str(yaml_path),\n",
    "    imgsz=640,           # increase detail for 4 keypoints\n",
    "    epochs=40,          # short FT round\n",
    "    patience=10,\n",
    "    lr0=0.002, lrf=0.05,  # smaller LR for fine-tune\n",
    "    batch=6,            # adjust to your VRAM\n",
    "    device=0 if torch.cuda.is_available() else 'cpu',\n",
    "    workers=WORKERS,    # slightly lower to reduce RAM footprint\n",
    "    project='runs',\n",
    "    name='pose_plate_ft',  # new run name to keep old run intact\n",
    "    exist_ok=True,\n",
    "    pretrained=False,\n",
    "    cache=CACHE_MODE,   # avoid huge RAM spikes by default; opt-in via YOLO_RAM_CACHE=1\n",
    "    plots=False,        # reduce overhead\n",
    "    save_period=0,      # save only best/last\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "results = model.train(**train_args)\n",
    "print('Fine-tune done. Best:', results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
