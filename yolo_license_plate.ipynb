{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "728b10c5",
   "metadata": {},
   "source": [
    "# YOLO License Plate Recognition - Tá»« Zero Ä‘áº¿n Hero\n",
    "\n",
    "Notebook nÃ y sáº½ hÆ°á»›ng dáº«n báº¡n:\n",
    "1. Hiá»ƒu YOLO hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o\n",
    "2. Cháº¡y YOLO cÃ³ sáºµn Ä‘á»ƒ detect Ä‘á»‘i tÆ°á»£ng\n",
    "3. Fine-tune YOLO cho biá»ƒn sá»‘ xe Viá»‡t Nam\n",
    "4. Tá»‘i Æ°u cho real-time processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dd696d",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 1: Import thÆ° viá»‡n vÃ  kiá»ƒm tra cÃ i Ä‘áº·t\n",
    "\n",
    "TrÆ°á»›c tiÃªn, hÃ£y cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t:\n",
    "```bash\n",
    "pip install ultralytics torch torchvision pillow matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c24b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eba0887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ultralytics YOLO Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t thÃ nh cÃ´ng!\n",
      "âœ… PyTorch version: 2.8.0+cu128\n",
      "âœ… CUDA available: True\n",
      "âœ… GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Import YOLO tá»« Ultralytics\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    print('âœ… Ultralytics YOLO Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t thÃ nh cÃ´ng!')\n",
    "except ImportError:\n",
    "    print('âŒ Cáº§n cÃ i Ä‘áº·t: pip install ultralytics')\n",
    "\n",
    "# Kiá»ƒm tra PyTorch\n",
    "try:\n",
    "    import torch\n",
    "    print(f'âœ… PyTorch version: {torch.__version__}')\n",
    "    print(f'âœ… CUDA available: {torch.cuda.is_available()}')\n",
    "    if torch.cuda.is_available():\n",
    "        print(f'âœ… GPU: {torch.cuda.get_device_name(0)}')\n",
    "    else:\n",
    "        print('âš ï¸  GPU khÃ´ng cÃ³ sáºµn, sáº½ dÃ¹ng CPU (cháº­m hÆ¡n)')\n",
    "except ImportError:\n",
    "    print('âŒ Cáº§n cÃ i Ä‘áº·t: pip install torch torchvision')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c76f06a",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 2: Táº£i vÃ  cháº¡y thá»­ YOLO cÃ³ sáºµn\n",
    "\n",
    "ChÃºng ta sáº½ báº¯t Ä‘áº§u vá»›i model YOLOv8 Ä‘Ã£ Ä‘Æ°á»£c train trÃªn COCO dataset (80 classes bao gá»“m xe, ngÆ°á»i, v.v.)\n",
    "\n",
    "**Giáº£i thÃ­ch:**\n",
    "- `yolov8n.pt`: nano version (nhá» nháº¥t, nhanh nháº¥t)\n",
    "- `yolov8s.pt`: small version\n",
    "- `yolov8m.pt`: medium version\n",
    "- `yolov8l.pt`: large version\n",
    "- `yolov8x.pt`: extra large (chÃ­nh xÃ¡c nháº¥t, cháº­m nháº¥t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901f5dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº£i model YOLO cÃ³ sáºµn (sáº½ tá»± Ä‘á»™ng download láº§n Ä‘áº§u)\n",
    "print(\"ğŸ“¥ Äang táº£i YOLOv8 nano model...\")\n",
    "model = YOLO(\"yolov8n.pt\")  # DÃ¹ng nano version cho tá»‘c Ä‘á»™\n",
    "\n",
    "print(\"âœ… Model Ä‘Ã£ sáºµn sÃ ng!\")\n",
    "print(f\"ğŸ“Š Model cÃ³ thá»ƒ detect {len(model.names)} classes:\")\n",
    "\n",
    "# In ra cÃ¡c class model cÃ³ thá»ƒ detect\n",
    "for i, name in model.names.items():\n",
    "    print(f\"{i:2d}: {name}\")\n",
    "\n",
    "# TÃ¬m class liÃªn quan Ä‘áº¿n vehicle\n",
    "vehicle_classes = [\n",
    "    (i, name)\n",
    "    for i, name in model.names.items()\n",
    "    if any(keyword in name.lower() for keyword in [\"car\", \"truck\", \"bus\", \"motorcycle\"])\n",
    "]\n",
    "print(f\"\\nğŸš— Vehicle classes: {vehicle_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d60cfd",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 3: Test Model Performance\n",
    "\n",
    "BÃ¢y giá» ta sáº½ test model vá»›i:\n",
    "1. **áº¢nh demo** cÃ³ biá»ƒn sá»‘ xe Viá»‡t Nam\n",
    "2. **Äo tá»‘c Ä‘á»™ inference** (FPS) Ä‘á»ƒ Ä‘áº£m báº£o Ä‘áº¡t yÃªu cáº§u 4-10 FPS\n",
    "3. **Visualize káº¿t quáº£** Ä‘á»ƒ hiá»ƒu model detect Ä‘Æ°á»£c gÃ¬\n",
    "4. **PhÃ¢n tÃ­ch gap** giá»¯a káº¿t quáº£ hiá»‡n táº¡i vs má»¥c tiÃªu\n",
    "\n",
    "**LÆ°u Ã½:** Model hiá»‡n táº¡i chÆ°a Ä‘Æ°á»£c train cho biá»ƒn sá»‘, nÃªn káº¿t quáº£ sáº½ khÃ´ng hoÃ n háº£o. ÄÃ¢y lÃ  baseline Ä‘á»ƒ so sÃ¡nh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8501d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load áº£nh tháº­t tá»« thÆ° má»¥c images/ Ä‘á»ƒ test\n",
    "def list_images(folder='images'):\n",
    "    exts = ('.jpg', '.jpeg', '.png', '.bmp')\n",
    "    folder_path = Path(folder)\n",
    "    if not folder_path.exists():\n",
    "        folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    files = [p for p in folder_path.iterdir() if p.suffix.lower() in exts]\n",
    "    return sorted(files)\n",
    "\n",
    "image_files = list_images('images')\n",
    "\n",
    "if not image_files:\n",
    "    print('âš ï¸ KhÃ´ng tÃ¬m tháº¥y áº£nh trong thÆ° má»¥c images/')\n",
    "    print('ğŸ‘‰ HÃ£y thÃªm má»™t vÃ i áº£nh biá»ƒn sá»‘ tháº­t vÃ o thÆ° má»¥c: images/')\n",
    "    print('VÃ­ dá»¥ tÃªn file: car1.jpg, plate01.png ...')\n",
    "else:\n",
    "    print(f'ğŸ“ TÃ¬m tháº¥y {len(image_files)} áº£nh:')\n",
    "    for idx, fp in enumerate(image_files):\n",
    "        print(f'  [{idx}] {fp.name}')\n",
    "    \n",
    "    # Chá»n áº£nh theo index\n",
    "    idx = 0  # Báº¡n cÃ³ thá»ƒ Ä‘á»•i sá»‘ nÃ y Ä‘á»ƒ chá»n áº£nh khÃ¡c\n",
    "    selected_image_path = image_files[idx]\n",
    "    print(f'\\nâœ… Äang dÃ¹ng áº£nh: {selected_image_path.name}')\n",
    "    \n",
    "    # Load áº£nh\n",
    "    real_img = cv2.imread(str(selected_image_path))\n",
    "    if real_img is None:\n",
    "        print('âŒ KhÃ´ng load Ä‘Æ°á»£c áº£nh (cÃ³ thá»ƒ file há»ng).')\n",
    "    else:\n",
    "        # Hiá»ƒn thá»‹ áº£nh\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(cv2.cvtColor(real_img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'ğŸ–¼ï¸ áº¢nh tháº­t: {selected_image_path.name}', fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # GÃ¡n áº£nh nÃ y lÃ m áº£nh test cho YOLO\n",
    "        demo_img = real_img.copy()\n",
    "        print('ğŸ”„ ÄÃ£ thay áº£nh demo báº±ng áº£nh tháº­t Ä‘á»ƒ inference!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3f4d049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Running YOLO detection on demo image...\n",
      "\n",
      "ğŸ“Š **DETECTION RESULTS:**\n",
      "ğŸ”¢ Number of detections: 0\n",
      "âŒ No objects detected!\n",
      "ğŸ’­ Possible reasons:\n",
      "   - Model confidence threshold too high\n",
      "   - Demo image too simple/synthetic\n",
      "   - Need to adjust inference parameters\n",
      "\n",
      "ğŸ¯ **NEXT STEP:** Äo tá»‘c Ä‘á»™ inference (FPS testing)\n"
     ]
    }
   ],
   "source": [
    "# Cháº¡y YOLO inference trÃªn áº£nh demo\n",
    "print('ğŸ” Running YOLO detection on demo image...')\n",
    "\n",
    "# Inference (cháº¡y model)\n",
    "results = model(demo_img, verbose=False)\n",
    "\n",
    "# Láº¥y káº¿t quáº£ Ä‘áº§u tiÃªn\n",
    "result = results[0]\n",
    "boxes = result.boxes\n",
    "\n",
    "print(f'\\nğŸ“Š **DETECTION RESULTS:**')\n",
    "print(f'ğŸ”¢ Number of detections: {len(boxes) if boxes is not None else 0}')\n",
    "\n",
    "# PhÃ¢n tÃ­ch tá»«ng detection\n",
    "if boxes is not None and len(boxes) > 0:\n",
    "    print('\\nğŸ“‹ **DETECTED OBJECTS:**')\n",
    "    for i, box in enumerate(boxes):\n",
    "        # Extract thÃ´ng tin tá»« box\n",
    "        xyxy = box.xyxy[0].cpu().numpy()  # [x1, y1, x2, y2]\n",
    "        conf = float(box.conf[0].cpu().numpy())  # confidence score\n",
    "        cls = int(box.cls[0].cpu().numpy())      # class id\n",
    "        class_name = model.names[cls]\n",
    "        \n",
    "        x1, y1, x2, y2 = xyxy\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        \n",
    "        print(f'   Detection {i+1}:')\n",
    "        print(f'     ğŸ·ï¸  Class: {class_name} (ID: {cls})')\n",
    "        print(f'     ğŸ“Š Confidence: {conf:.3f} ({conf*100:.1f}%)')\n",
    "        print(f'     ğŸ“ Bounding box: ({x1:.0f}, {y1:.0f}) â†’ ({x2:.0f}, {y2:.0f})')\n",
    "        print(f'     ğŸ“ Size: {width:.0f} Ã— {height:.0f} pixels')\n",
    "        \n",
    "        # Check if detected the license plate area\n",
    "        if 230 <= (x1+x2)/2 <= 390 and 350 <= (y1+y2)/2 <= 410:\n",
    "            print(f'     âœ… CÃ³ thá»ƒ Ä‘Ã¢y lÃ  vÃ¹ng biá»ƒn sá»‘!')\n",
    "        print()\n",
    "\n",
    "    # Visualize káº¿t quáº£\n",
    "    annotated_img = result.plot(line_width=3, font_size=16)\n",
    "    \n",
    "    # Display side-by-side comparison\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(demo_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('ğŸ–¼ï¸ Original Demo Image', fontsize=14, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('ğŸ¯ YOLO Detection Results', fontsize=14, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print('âŒ No objects detected!')\n",
    "    print('ğŸ’­ Possible reasons:')\n",
    "    print('   - Model confidence threshold too high')\n",
    "    print('   - Demo image too simple/synthetic')\n",
    "    print('   - Need to adjust inference parameters')\n",
    "\n",
    "print('\\nğŸ¯ **NEXT STEP:** Äo tá»‘c Ä‘á»™ inference (FPS testing)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27bd493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark tá»‘c Ä‘á»™ inference Ä‘á»ƒ Ä‘áº£m báº£o Ä‘áº¡t 4-10 FPS\n",
    "import time\n",
    "\n",
    "print('â±ï¸ Testing inference speed...')\n",
    "\n",
    "# Táº¡o áº£nh dummy Ä‘á»ƒ test (640x640 standard YOLO input)\n",
    "dummy_image = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)\n",
    "\n",
    "# Warm-up (model cáº§n má»™t vÃ i láº§n cháº¡y Ä‘áº§u Ä‘á»ƒ tá»‘i Æ°u)\n",
    "print('ğŸ”¥ Warming up model...')\n",
    "for _ in range(3):\n",
    "    _ = model(dummy_image, verbose=False)\n",
    "\n",
    "# Benchmark thá»±c táº¿\n",
    "print('ğŸ“Š Running benchmark (10 iterations)...')\n",
    "times = []\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    results = model(dummy_image, verbose=False)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    inference_time = end_time - start_time\n",
    "    fps = 1 / inference_time\n",
    "    times.append(inference_time)\n",
    "    \n",
    "    print(f'  Frame {i+1}: {inference_time*1000:.1f}ms â†’ {fps:.1f} FPS')\n",
    "\n",
    "# Thá»‘ng kÃª\n",
    "avg_time = np.mean(times)\n",
    "avg_fps = 1 / avg_time\n",
    "min_time = np.min(times)\n",
    "max_fps = 1 / min_time\n",
    "\n",
    "print(f'\\nğŸ“ˆ **PERFORMANCE SUMMARY:**')\n",
    "print(f'â±ï¸  Average inference time: {avg_time*1000:.1f}ms')\n",
    "print(f'ğŸš€ Average FPS: {avg_fps:.1f}')\n",
    "print(f'ğŸ† Best FPS: {max_fps:.1f}')\n",
    "print(f'ğŸ¯ Target range: 4-10 FPS')\n",
    "\n",
    "# ÄÃ¡nh giÃ¡ káº¿t quáº£\n",
    "if avg_fps < 4:\n",
    "    print('âŒ **PERFORMANCE: TOO SLOW**')\n",
    "    print('ğŸ’¡ Recommendations:')\n",
    "    print('   - Giáº£m input size: 640â†’480 hoáº·c 320')\n",
    "    print('   - Sá»­ dá»¥ng GPU náº¿u cÃ³')\n",
    "    print('   - Consider model quantization')\n",
    "elif avg_fps > 10:\n",
    "    print('âœ… **PERFORMANCE: EXCELLENT!**')\n",
    "    print('ğŸ‰ Options:')\n",
    "    print('   - CÃ³ thá»ƒ tÄƒng input size â†’ better accuracy')\n",
    "    print('   - Hoáº·c dÃ¹ng model lá»›n hÆ¡n (yolov8s)')\n",
    "    print('   - Hardware cá»§a báº¡n ráº¥t tá»‘t!')\n",
    "else:\n",
    "    print('âœ… **PERFORMANCE: PERFECT!**')\n",
    "    print('ğŸ¯ Äáº¡t chÃ­nh xÃ¡c target range 4-10 FPS')\n",
    "    print('âš¡ Sáºµn sÃ ng cho real-time processing!')\n",
    "\n",
    "print(f'\\nğŸ’» **SYSTEM INFO:**')\n",
    "print(f'ğŸ”§ Model: YOLOv8n')\n",
    "print(f'ğŸ–¼ï¸  Input size: 640x640')\n",
    "print(f'ğŸ® Device: {\"GPU\" if torch.cuda.is_available() else \"CPU\"}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
